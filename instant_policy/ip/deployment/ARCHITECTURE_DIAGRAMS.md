# Instant Policy Deployment: Complete System Architecture

This diagram captures the complete deployment system - hardware, software, data flow, and control flow in a single comprehensive view.

---

```mermaid
flowchart TB
    %% ==================== HARDWARE LAYER ====================
    subgraph HARDWARE["âš™ï¸ HARDWARE LAYER"]
        direction LR
        
        subgraph Robot["ğŸ¤– UR5e Robot @ 192.168.1.102"]
            URBase["Base Frame (W)"]
            URTCP["TCP Frame (E)"]
            URController["Controller<br/>RTDE @ 500Hz"]
            URDashboard["Dashboard<br/>Port 29999"]
        end
        
        subgraph Gripper["ğŸ”§ Robotiq 2F-85"]
            GripperSocket["TCP Socket<br/>Port 63352"]
            GripperMech["Position: 0-255<br/>Speed: 0-255<br/>Force: 0-255"]
        end
        
        subgraph Cameras["ğŸ“· Intel RealSense (Ã—1-2)"]
            RS_Color["Color Stream<br/>640Ã—480 @ 30fps<br/>RGB8"]
            RS_Depth["Depth Stream<br/>640Ã—480 @ 30fps<br/>Z16"]
            RS_Intrinsics["Intrinsics K<br/>fx, fy, cx, cy"]
        end
    end

    %% ==================== CONFIGURATION ====================
    subgraph CONFIG["ğŸ“‹ CONFIGURATION (config.py)"]
        direction TB
        
        DeploymentConfig["DeploymentConfig<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>robot_ip: 192.168.1.102<br/>model_path: ./checkpoints<br/>num_demos: 2<br/>num_traj_wp: 10<br/>pcd_num_points: 2048<br/>device: cuda:0"]
        
        CameraConfig["CameraConfig<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>serial: str<br/>T_world_camera: [4,4]<br/>width, height, fps<br/>align_to_color: true"]
        
        SegConfig["SegmentationConfig<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>backend: xmem<br/>sam_checkpoint<br/>xmem_checkpoint<br/>xmem_init_with_sam: true"]
        
        SafetyConfig["SafetyLimits<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>workspace: [0.2,-0.4,0.05]<br/>         â†’ [0.7,0.4,0.5]<br/>max_trans: 0.01m<br/>max_rot: 3Â°"]
        
        RTDEConfig["RTDEControlConfig<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>mode: moveL/servoL<br/>speed: 0.1 m/s<br/>accel: 0.5 m/sÂ²"]
        
        GripConfig["GripperConfig<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>port: 63352<br/>open_pos: 0<br/>closed_pos: 255"]
    end

    %% ==================== PERCEPTION PIPELINE ====================
    subgraph PERCEPTION["ğŸ‘ï¸ PERCEPTION PIPELINE (perception/)"]
        direction TB
        
        subgraph RSCapture["RealSensePerception.capture_pcd_world()"]
            direction TB
            WaitFrames["1ï¸âƒ£ pipeline.wait_for_frames()"]
            AlignFrames["2ï¸âƒ£ rs.align(color).process()"]
            GetArrays["3ï¸âƒ£ depth = frame.get_data() Ã— scale<br/>    color = frame.get_data()"]
        end
        
        subgraph Segmentation["XMemOnlineSegmenter / SAMSegmenter"]
            direction TB
            CheckInit{"Initialized?"}
            SAMSeed["SAM: segment(rgb)<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>SamAutomaticMaskGenerator<br/>points_per_side: 32<br/>pred_iou_thresh: 0.88<br/>â†’ largest component"]
            XMemInit["XMem: initialize<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>clear_memory()<br/>set_all_labels([1])<br/>put_to_permanent_memory()"]
            XMemTrack["XMem: track<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>processor.step(image)<br/>argmax(prob) â†’ mask"]
        end
        
        subgraph PointCloud["Point Cloud Generation"]
            direction TB
            ApplyMask["4ï¸âƒ£ depth_masked = depth Ã— mask"]
            BackProject["5ï¸âƒ£ xyz_c = inv(K) @ [u,v,1] Ã— d<br/>    Filter: isfinite & z>0"]
            ToWorld["6ï¸âƒ£ xyz_w = T_world_camera @ xyz_c"]
            Fuse["7ï¸âƒ£ Concatenate all cameras"]
            VoxelDown["8ï¸âƒ£ voxel_downsample(size)"]
        end
    end

    %% ==================== STATE ESTIMATION ====================
    subgraph STATE["ğŸ“Š STATE (state/)"]
        direction TB
        
        subgraph URState["URRTDEState"]
            GetPose["get_T_w_e()<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>pose = rtde.getActualTCPPose()<br/>[x,y,z,rx,ry,rz]<br/>â†“<br/>T[:3,3] = xyz<br/>T[:3,:3] = Rotation.from_rotvec(rpy)"]
            GetGrip["get_gripper_state()<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>pos = gripper.get_position()<br/>normalize: (pos-open)/(closed-open)<br/>â†’ [0, 1]"]
        end
    end

    %% ==================== MAIN ORCHESTRATOR ====================
    subgraph ORCHESTRATOR["ğŸ¯ ORCHESTRATOR (orchestrator.py)"]
        direction TB
        
        subgraph Init["__init__()"]
            BuildSeg["Build segmenter (SAM/XMem)"]
            BuildPerception["Build RealSensePerception"]
            ConnectGripper["Connect RobotiqGripper"]
            ConnectRTDE["Connect RTDE Control + Receive"]
            BuildState["Build URRTDEState"]
            BuildControl["Build URRTDEControl"]
            BuildExecutor["Build ActionExecutor"]
            LoadModel["Load GraphDiffusion"]
        end
        
        subgraph PrepDemos["_prepare_demos()"]
            ConvertDemo["sample_to_cond_demo()<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>Select L=10 waypoints<br/>Convert pcd â†’ EE frame<br/>Pad if fewer demos"]
        end
        
        subgraph MainLoop["run() - Main Loop"]
            direction TB
            
            Step1["ğŸ“ STEP 1: Capture State<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>T_w_e = state.get_T_w_e()<br/>grip = state.get_gripper_state()<br/>grip = 1 if gripâ‰¥0.5 else 0"]
            
            Step2["ğŸ“· STEP 2: Capture Perception<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>pcd_w = perception.capture_pcd_world()"]
            
            Step3["ğŸ”„ STEP 3: Transform to EE<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>pcd_ee = inv(T_w_e) @ pcd_w<br/>subsample â†’ [2048, 3]"]
            
            Step4["ğŸ“¦ STEP 4: Build Sample<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>full_sample = {<br/>  demos: [...],<br/>  live: {obs, grips, T_w_es}<br/>}<br/>data = save_sample()"]
            
            Step5["ğŸ§  STEP 5: Model Inference<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>if step==0: cache demo_embds<br/>live_embds = get_live_scene_emb()<br/>actions, grips = model.test_step()"]
            
            Step6["ğŸ® STEP 6: Execute<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>executor.execute_actions(<br/>  actions, grips,<br/>  T_w_e_initial,<br/>  horizon<br/>)"]
        end
    end

    %% ==================== MODEL ====================
    subgraph MODEL["ğŸ§  MODEL (GraphDiffusion)"]
        direction TB
        
        ModelLoad["load_from_checkpoint()<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>config.pkl + model.pt<br/>batch_size=1<br/>num_diffusion_iters=4"]
        
        DemoEmb["get_demo_scene_emb()<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>Encode N demo point clouds<br/>â†’ demo_embds, demo_pos<br/>(cached at step 0)"]
        
        LiveEmb["get_live_scene_emb()<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>Encode live point cloud<br/>â†’ live_embds, live_pos"]
        
        Diffusion["test_step()<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>Diffusion denoising<br/>4 iterations<br/>â†’ actions [8,4,4]<br/>â†’ grips [8] âˆˆ {-1,1}"]
    end

    %% ==================== CONTROL ====================
    subgraph CONTROL["ğŸ® CONTROL (control/)"]
        direction TB
        
        subgraph ActionExec["ActionExecutor.execute_actions()"]
            direction TB
            
            ActionLoop["for j in range(horizon):"]
            
            Compose["T_target = T_initial @ actions[j]<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>Actions are CUMULATIVE<br/>relative to inference pose"]
            
            SafetyCheck["Safety Checks<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>âœ“ pos âˆˆ workspace bounds<br/>âœ“ â€–Î”posâ€– â‰¤ 1cm<br/>âœ“ â€–Î”rotâ€– â‰¤ 3Â°"]
            
            ExecutePose["URRTDEControl.execute_pose()<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>pose = [x,y,z,rx,ry,rz]<br/>moveL(pose, speed, accel)<br/>  or<br/>servoL(pose, ...)"]
            
            ExecuteGrip["URRTDEControl.execute_gripper()<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>cmd = (grip+1)/2<br/>cmd>0.5 ? open() : close()"]
        end
    end

    %% ==================== GRIPPER DRIVER ====================
    subgraph GRIPPER_DRIVER["ğŸ”§ GRIPPER (ur/robotiq_gripper.py)"]
        direction TB
        
        GripperProto["Socket Protocol (Port 63352)<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>SET ACT 1 â†’ ack (activate)<br/>SET POS N â†’ ack (position)<br/>SET SPE N â†’ ack (speed)<br/>SET FOR N â†’ ack (force)<br/>SET GTO 1 â†’ ack (go)<br/>GET POS â†’ POS N (read)"]
        
        GripperMethods["Methods<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>connect() â†’ TCP socket<br/>activate() â†’ reset + ACT=1<br/>move(pos, speed, force)<br/>open() / close()<br/>get_position_normalized()"]
    end

    %% ==================== KEYBOARD INPUT ====================
    subgraph KEYBOARD["âŒ¨ï¸ KEYBOARD INPUT (pynput)"]
        direction TB
        
        KeyListener["Keyboard Listener<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>O â†’ gripper.open()<br/>C â†’ gripper.close()<br/>Q/ESC â†’ stop recording"]
    end

    %% ==================== DEMO COLLECTION ====================
    subgraph DEMO["ğŸ“¹ DEMO COLLECTION (demo/)"]
        direction TB
        
        DemoCollect["DemoCollector.collect_kinesthetic()<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>1. Press ENTER â†’ enable_freedrive()<br/>2. Guide robot by hand<br/>3. Press O/C â†’ open/close gripper<br/>4. Loop @ 10Hz:<br/>   â€¢ capture pcd_w<br/>   â€¢ capture T_w_e<br/>   â€¢ capture grip<br/>5. Press Q/ESC â†’ stop<br/>6. disable_freedrive()<br/>7. Save to demo.pkl"]
        
        DemoConvert["prepare_for_model()<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>sample_to_cond_demo()<br/>â†’ 10 waypoints<br/>â†’ pcd in EE frame"]
        
        DemoFormat["Demo Format (.pkl)<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>pcds: List[ndarray]<br/>T_w_es: List[4x4]<br/>grips: List[0 or 1]"]
    end

    %% ==================== DATA SHAPES ====================
    subgraph SHAPES["ğŸ“ DATA SHAPES & UNITS"]
        direction TB
        
        Tensors["Key Tensors<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>pcd_w: [N, 3] float32 meters (world)<br/>pcd_ee: [2048, 3] float32 meters (EE)<br/>T_w_e: [4, 4] float32<br/>actions: [8, 4, 4] float32 (relative)<br/>grips: [8] float32 âˆˆ {-1, 1}"]
        
        Frames["Coordinate Frames<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>C: Camera (RealSense optical)<br/>W: World (UR base)<br/>E: End-Effector (UR TCP)<br/><br/>C â†’ W: T_world_camera<br/>W â†’ E: inv(T_w_e)"]
    end

    %% ==================== CONNECTIONS ====================
    
    %% Hardware to Drivers
    RS_Color & RS_Depth --> WaitFrames
    RS_Intrinsics --> BackProject
    URController --> GetPose
    GripperSocket --> GripperProto
    
    %% Config connections
    DeploymentConfig --> BuildSeg
    CameraConfig --> BuildPerception
    SegConfig --> BuildSeg
    RTDEConfig --> ConnectRTDE
    GripConfig --> ConnectGripper
    SafetyConfig --> BuildExecutor
    
    %% Perception flow
    WaitFrames --> AlignFrames --> GetArrays
    GetArrays --> CheckInit
    CheckInit -->|No| SAMSeed --> XMemInit --> ApplyMask
    CheckInit -->|Yes| XMemTrack --> ApplyMask
    ApplyMask --> BackProject --> ToWorld --> Fuse --> VoxelDown
    
    %% State flow
    GetPose --> Step1
    GetGrip --> Step1
    
    %% Main loop flow
    VoxelDown --> Step2
    Step1 --> Step2 --> Step3 --> Step4 --> Step5 --> Step6
    
    %% Model flow
    Step4 --> DemoEmb
    Step4 --> LiveEmb
    DemoEmb & LiveEmb --> Diffusion
    Diffusion --> Step6
    
    %% Control flow
    Step6 --> ActionLoop
    ActionLoop --> Compose --> SafetyCheck
    SafetyCheck -->|Pass| ExecutePose --> ExecuteGrip
    SafetyCheck -->|Fail| Step1
    ExecuteGrip --> Step1
    
    %% Gripper control
    ExecuteGrip --> GripperProto
    GripperProto --> GripperMech
    
    %% Robot control
    ExecutePose --> URController
    
    %% Demo collection
    BuildPerception --> DemoCollect
    BuildState --> DemoCollect
    BuildControl --> DemoCollect
    KeyListener --> DemoCollect
    DemoCollect --> DemoFormat
    DemoCollect --> DemoConvert --> PrepDemos

    %% Styling
    classDef hardware fill:#FFE4B5,stroke:#D2691E,stroke-width:2px
    classDef config fill:#E6E6FA,stroke:#9370DB,stroke-width:2px
    classDef perception fill:#B0E0E6,stroke:#4682B4,stroke-width:2px
    classDef state fill:#98FB98,stroke:#228B22,stroke-width:2px
    classDef orchestrator fill:#FFB6C1,stroke:#DC143C,stroke-width:2px
    classDef model fill:#DDA0DD,stroke:#8B008B,stroke-width:2px
    classDef control fill:#F0E68C,stroke:#DAA520,stroke-width:2px
    classDef gripper fill:#FFA07A,stroke:#FF4500,stroke-width:2px
    classDef demo fill:#87CEEB,stroke:#1E90FF,stroke-width:2px
    classDef shapes fill:#D3D3D3,stroke:#696969,stroke-width:2px
    
    class Robot,Gripper,Cameras hardware
    class DeploymentConfig,CameraConfig,SegConfig,SafetyConfig,RTDEConfig,GripConfig config
    class RSCapture,Segmentation,PointCloud perception
    class URState state
    class Init,PrepDemos,MainLoop orchestrator
    class ModelLoad,DemoEmb,LiveEmb,Diffusion model
    class ActionExec control
    class GripperProto,GripperMethods gripper
    class DemoCollect,DemoConvert demo
    class Tensors,Frames shapes
```

---

## Legend

| Color      | Component                          |
| ---------- | ---------------------------------- |
| ğŸŸ  Orange   | Hardware (Robot, Gripper, Cameras) |
| ğŸŸ£ Purple   | Configuration                      |
| ğŸ”µ Blue     | Perception Pipeline                |
| ğŸŸ¢ Green    | State Estimation                   |
| ğŸ”´ Pink     | Orchestrator                       |
| ğŸŸ£ Magenta  | Model                              |
| ğŸŸ¡ Yellow   | Control                            |
| ğŸŸ  Salmon   | Gripper Driver                     |
| ğŸ”µ Sky Blue | Demo Collection                    |
| âšª Gray     | Data Shapes                        |

---

## Key Data Flow Summary

1. **Cameras** â†’ `RealSensePerception` â†’ RGB-D frames
2. **XMem++** (seeded by SAM) â†’ segmentation mask
3. **Back-projection** with intrinsics K â†’ camera-frame points
4. **T_world_camera** â†’ world-frame points
5. **inv(T_w_e)** â†’ EE-frame points (model input)
6. **GraphDiffusion** â†’ actions `[8,4,4]`, grips `[8]`
7. **ActionExecutor** â†’ safety check â†’ `moveL`/`servoL`
8. **RobotiqGripper** â†’ socket protocol â†’ gripper motion
